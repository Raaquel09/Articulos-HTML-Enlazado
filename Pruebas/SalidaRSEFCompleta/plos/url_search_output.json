[
    {
        "title": "Quantifying Reproducibility in Computational Biology: The Case of the Tuberculosis Drugome",
        "implementation_urls": [],
        "doi": "10.1371/journal.pone.0080278",
        "abstract": "AbstractHow easy is it to reproduce the results found in a typical computational biology paper? Either through experience orintuition the reader will already know that the answer is with difficulty or not at all. In this paper we attempt to quantify thisdifficulty by reproducing a previously published paper for different classes of users (ranging from users with little expertiseto domain experts) and suggest ways in which the situation might be improved. Quantification is achieved by estimatingthe time required to reproduce each of the steps in the method described in the original paper and make them part of anexplicit workflow that reproduces the original results. Reproducing the method took several months of effort, and requiredusing new versions and new software that posed challenges to reconstructing and validating the results. The quantificationleads to ‘‘reproducibility maps’’ that reveal that novice researchers would only be able to reproduce a few of the steps in themethod, and that only expert researchers with advance knowledge of the domain would be able to reproduce the methodin its entirety. The workflow itself is published as an online resource together with supporting software and data. The paperconcludes with a brief discussion of the complexities of requiring reproducibility in terms of cost versus benefit, and adesiderata with our observations and guidelines for improving reproducibility. This has implications not only in reproducingthe work of others from published papers, but reproducing work from one’s own laboratory.Citation: Garijo D, Kinnings S, Xie L, Xie L, Zhang Y, et al. (2013) Quantifying Reproducibility in Computational Biology: The Case of the TuberculosisDrugome. PLoS ONE 8(11): e80278. doi:10.1371/journal.pone.0080278Editor: Christos A. Ouzounis, The Centre for Research and Technology, Hellas, GreeceReceived September 18, 2012; Accepted October 10, 2013; Published November 27, 2013Copyright: � 2013 Garijo et al. This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permitsunrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Funding: This research is sponsored by Elsevier Labs, the National Science Foundation with award number -0 , the Air Force Office of ScientificResearch with award number FA9550-11-1-0104, internal funds from the University of Southern California’s Information Sciences Institute and from the Universityof California, San Diego, and by a Formacistudy design, data collection and analysis, decision to publish, or preparation of the manuscript.Competing Interests: The research presented here has been sponsored partly by Elsevier Labs. This does not alter the authors’ adherence to all the PLOS ONEpolicies on sharing data and materials.* E-mail: pbourne@ucsd.edu (PEB); gil@isi.edu (YG)IntroductionComputation is now an integral part of the biological scienceseither applied as a technique or as a science in its own right -bioinformatics. As a technique, software becomes an instrument toanalyze data and uncover new biological insights. By reading thepublished article describing these insights, another researcherhopes to understand what computations were carried out, replicatethe software apparatus originally used and reproduce theexperiment. This is rarely the case without significant effort, andsometimes impossible without asking the original authors. In short,reproducibility in computational biology is aspired to, but rarelyachieved. This is unfortunate since the quantitative nature of thescience makes reproducibility more obtainable than in cases whereexperiments are qualitative and hard to describe explicitly.An intriguing possibility where potential quantification exists isto extend articles through the inclusion of scientific workflows thatrepresent computations carried out to obtain the published results,thereby capturing data analysis methods explicitly [1]. This wouldmake scientific results more reproducible because articles wouldhave not only a textual description of the computational processdescribed in the article but also a workflow that, as acomputational artifact, could be analyzed and re-run automati-cally. Consequently, workflows can make scientists more produc-",
        "publication_date": "2013-11-27",
        "authors": "Daniel Garijo, Sarah Kinnings, Li Xie, Lei Xie, Yinliang Zhang, Philip E. Bourne, Yolanda Gil",
        "file_name": "20250512001137.pdf",
        "file_path": "../Pruebas/SalidaRSEFCompleta/plos/PDFs/20250512001137.pdf",
        "pdf_link": "https://dgarijo.com/papers/plos.pdf"
    }
]