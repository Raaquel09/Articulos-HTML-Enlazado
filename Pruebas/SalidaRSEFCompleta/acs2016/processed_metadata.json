[
    {
        "title": "Automated Hypothesis Testing with Large Scientific Data Repositories",
        "implementation_urls": [],
        "doi": null,
        "arxiv": null,
        "abstract": "Abstract The automation of important aspects of scientific data analysis would significantly accelerate the pace of science and innovation. Although there has been a lot of work done towards that automation, the hypothesize-test-evaluate discovery cycle is still largely carried out by hand by researchers.  This introduces a significant human bottleneck, which leads to inefficiencies, potential errors, and incomplete explorations of the hypothesis and data analysis space. We introduce a novel approach to automate the hypothesize-test-evaluate discovery cycle with an intelligent system that a scientist can task to test hypotheses of interest against a data repository. Our approach captures three types of data analytics knowledge: 1) common data analytic methods represented as semantic workflows; 2) meta-analysis methods that aggregate those results, represented as meta-workflows; and 3) data analysis strategies that specify for a type of hypothesis what data and methods to use, represented as lines of inquiry.  Given a hypothesis specified by a scientist, appropriate lines of inquiry are triggered, which lead to retrieving relevant datasets, running relevant workflows on that data, and finally running meta-workflows on workflow results.  The scientist is then presented with a level of confidence on the initial hypothesis, a revised hypothesis, and possibly with new hypotheses. We have implemented this approach in the DISK system, and applied it to multi-omics data analysis. 1.  Introduction The rate of data collection has vastly surpassed our ability to analyze it.  In science, massive amounts of data are already available in repositories, waiting to be analyzed [Tomczak et al 2015, Rudnick et al. 2016].  As these repositories are constantly growing, an analysis performed today may give different results when performed in the future. Data analytics expertise is not easily disseminated, and institutions have more data than experts to analyze it.  For example, in a recent survey of reviewers of Science magazine (which could be considered to be at the top of their field) a majority of respondents said that their lab did not have the necessary expertise to analyze Y. GIL, D. GARIJO, V. RATNAKAR, R. MAYANI, R. ADUSUMILLI, H. BOYCE, P. MALLICK  2 the data they already have [Science 2011].  The situation is likely worse for the vast majority of scientists, and in less privileged institutions and sectors.  Indeed, data analytic processes are currently carried out by hand by investigators, introducing a significant human bottleneck that can lead to erroneous and incomplete explorations, and hampers reproducibility [Begley and Ellis 2012].  The automation of important aspects of scientific discovery would significantly accelerate the pace of science and innovation. Although scientific discovery may involve complex representational and paradigm changes [Kuhn 1962], AI researchers have automated important aspects of discovery such as experiment design and testing [Kulkarni and Simon 1988; King et al 2009] and induction of laws from given datasets [Langley et al 1987; Valdes-Perez 1997; Todorovski et al 2000; Schmidt and Lipson 2009]. Once a representation is chosen, discovery processes often involve searching through the space of possible hypotheses and models.   Our goal is to develop an intelligent system able to conduct hypothesis-driven data analysis of science data repositories. In many science domains, comprehensive data repositories are being developed with large amounts of diverse data.  Given the necessary knowledge and methods, an intelligent system could autonomously analyze the data in a systematic, comprehensive, and efficient manner [Buchanan and Waltz 2009; Gil et al 2014]. Automating data analyses would also enforce consistency, as they would follow processes recognized by experts in the field of study.  In addition, automation would facilitate inspectability and reproducibility of results. In this paper we introduce a novel approach to automate the hypothesize-test-evaluate discovery cycle by capturing data analytics expertise and applying it to automatically test given hypotheses against existing data repositories.  Our approach captures three types of data analytics ",
        "publication_date": null,
        "authors": "",
        "file_name": "20250512001428.pdf",
        "file_path": "../Pruebas/SalidaRSEFCompleta/acs2016/PDFs/20250512001428.pdf",
        "pdf_link": "https://dgarijo.com/papers/acs2016.pdf"
    }
]