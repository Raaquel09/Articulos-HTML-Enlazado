[
    {
        "title": "LLMs for Ontology Engineering: A landscape of Tasks and",
        "implementation_urls": [],
        "doi": null,
        "arxiv": null,
        "abstract": "AbstractLarge Language Models (LLMs) have emerged as a powerful technology for text generation tasks, showingpromise in supporting the Ontology Engineering (OE) process. In this paper, we review current research onapplying LLMs to OE tasks, aiming to identify commonalities and gaps in the state of the art. We categorize theseefforts using the Linked Open Terms (LOT) methodology, characterizing them by their input and expected output.From this analysis, we highlight key challenges when creating benchmarks to evaluate LLM performance in OEtasks.KeywordsLarge Language Models, Ontology Engineering, Benchmark, Challenges1. IntroductionOntologies are a key component of Knowledge Engineering for integrating, validating and reasoningwith data in Knowledge Graphs [1]. However, developing ontologies is a challenging and time consumingtask. According to existing methodologies for ontology development [2], Knowledge Engineers shouldfollow an iterative process to 1) distill the knowledge of the target domain by interviewing expertsand understand their data-driven requirements, 2) implement a shared conceptualization by assessingexisting standard ontologies described in the domain and validating it against the requirements, 3) makethe ontology available on the web in both human and machine-readable manner, and 4) assess andmaintain the ontology by addressing any new requirements that may arise from its use. While differenttools have been developed by the scientific community to assist in the Ontology Engineerning process(e.g., for formalizing tests to assess requirements [3], creating human-readable documentation [4],ontology assessment [5, 6], etc.) a significant manual effort is still required from knowledge engineersfor conceptualizing, reusing and validating existing ontologies.In recent years, Large Language Models (LLMs) [7, 8, 9] have emerged as a disruptive AI technologyfor text generation tasks. On the one hand, LLMs have revolutionized the state of the art by providingimpressive results in challenging AI tasks such as code generation [10], question answering [11] ortext summarization [7], and becoming easy to adapt as chat bots such as ChatGPT.1 On the other hand,LLMs have limited reasoning skills [12], hallucination problems (i.e., producing inaccurate answers andinformation) [13], lack transparency when providing results [14] and present bias problems [15].A number of works have started using LLMs for aiding developers in ontology engineering tasks(e.g., proposing competency questions [16], learning ontologies from text [17], aligning concepts toexisting taxonomies [18], etc.). However, the tasks addressed in existing works are usually defined inan heterogeneous manner, with different scope, inputs and expected outputs. In this paper we providean overview of existing Ontology Engineering tasks addressed in the state of the art and map themISWC’24, Special Session on LLMs, November 11 - 15, 2024, Maryland, USAEnvelope-Open daniel.garijo@upm.es (D. Garijo); m.poveda@upm.es (M. Poveda-Villalón); elvira.amador@upm.es(E. Amador-Domínguez); ziyuan.wang@upm.es (Z. Wang); r.garcia@upm.es (R. García-Castro); oscar.corcho@upm.es(O. Corcho)Orcid 0000-0003-0454-7145 (D. Garijo); 0000-0003-3587-0367 (M. Poveda-Villalón); 0000-0001-6838-1266 (E. Amador-Domínguez);0009-0000-6228-4713 (Z. Wang); 0000-0002-0421-452X (R. García-Castro); 0000-0002-9260-0753 (O. Corcho)© 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).1https://chat.openai.com/mailto:daniel.garijo@upm.esmailto:m.poveda@upm.esmailto:elvira.amador@upm.esmailto:ziyuan.wang@upm.esmailto:r.garcia@upm.esmailto:oscar.corcho@upm.eshttps://orcid.org/0000-0003-0454-7145https://orcid.org/0000-0003-3587-0367https://orcid.org/0000-0001-6838-1266",
        "publication_date": null,
        "authors": "",
        "file_name": "20250511225701.pdf",
        "file_path": "../Pruebas/SalidaRSEFBasica/iswc_llm/PDFs/20250511225701.pdf",
        "pdf_link": "https://dgarijo.com/papers/iswc_llm.pdf"
    }
]